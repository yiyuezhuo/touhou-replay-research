\documentclass[UTF8]{ctexart}

\usepackage{float} 
\usepackage{amsmath}

\title{弹幕游戏的操作序列分析}
\author{卓越羿,郭煌,吴迪}

\begin{document}

\maketitle
\begin{abstract}

本文研究了东方系列弹幕游戏的操作序列，建立了基于贝叶斯推断的运用MCMC的仅根据操作序列对阶段进行分类的方法。
并对玩家使用的策略进行识别。

\textbf{关键字}: 贝叶斯推断，MCMC，游戏分析

\end{abstract}

\section{问题背景}

游戏正在耗费人类越来越多的时间，所以对于人类在电脑游戏这一形式化的系统上的行为的研究，
无论对于人类自身还是游戏的相关产业都是否有用。
而在对于游戏可能产生的数据，除了在现实中的响应外，最重要的应该是游戏内部的操作序列。
很多游戏可以记录玩家的操作序列，
通常被称为“回放”（replay）。这些回放仅仅包含操作信息，可以重新被游戏读取模拟玩家的操作，以无损失的重现一场游戏的过程。
这与现在流行的通过共享对游戏录制的视频是完全不同的，视频不用具有游戏即可以播放，但仅能记录画面的信息，
而这些画面信息完全可以由大小小多了的操作序列通过运行游戏重造出来。早期网络的网速较慢，
出于与现在视频流行类似的共享需求，回放技术得到了发展。

电脑游戏回放中可能最多的，是即时战略游戏的回放，虽然存在一些相关的分析
%（此处应有对kaggle那个星际争霸回放研究的引用，以及引用的引用），
\cite{starcraft}
但是这些信息比较复杂，
我们可以对比另外也许是“回放”很多的非电脑游戏，如国际象棋和围棋，可以以“棋谱”为形式记录它们，
有着它们行为空间固有的简单性。只需注意到这些游戏上的人工智能取得成就
%（此处引用alphago），
\cite{alphago}
就可以意识到这一点。对于类似的输入简单地游戏，
如那些游戏机上只通过手柄的有限的按键输入的游戏，人工智能也取得了类似的成就，
如有名的DQN算法
%（引用Atari游戏论文），
\cite{atari}
其必须基于输入的离散性。
我们这里也研究一种类似的游戏，即弹幕游戏（STG）。

弹幕游戏主要是玩家在操纵角色躲避敌方“弹幕”同时进行反击的游戏，
其挑战性主要在于玩家的反应速度与根据弹幕运动规律进行预判（被称为“底力”），
在更深度的玩家那里，记忆特定关卡的弹幕特征也是重要的（称为“背板”）。有名的弹幕游戏系列包括雷电，虫姬等，
我们这里研究玩家较多，从而积累下的回放数也较多的东方project系列，其中的第10部，风神录作为具体研究的游戏。

游戏的回放文件批量下载自回放存档网站royalflare\footnote{ http://score.royalflare.net/ }。
该网站保存了过往玩家自发上传的回放，通常属于打出彩的那种。
我们主要选择其中Lunatic难度（最高难度）“梦B型”的202个回放文件，其跨度从2007到2017年。

\section{原始数据类型与数据处理}

回放文件是二进制的，其包含元信息-关卡信息，关卡信息又包含关卡的元信息与该关卡的操作序列，
操作序列是整个回放文件的主要数据。

操作序列由一系列48bit的数据块构成，其表示一帧（frame，通常来说1秒=60frame）中的按键情况。
我们大致的实验揭示了以下部分重要按键与数据的关系：

\begin{verbatim}
000000000000000000000000000100000000000000000000
                       ***** ***                 
*标出的二进制位分别表示该帧正在按着 ctrl,right,left,down,up,shift,x,z
000000000001000000000000000101000000000000000000
       ***** ***                                
*标出的二进制位分别表示该帧刚刚按下了 ctrl,right,left,down,up,shift,x,z
000000000000000000000000000000000000000111110111
                                       ***** ***
*标出的二进制位分别表示该帧刚刚松开 ctrl,right,left,down,up,shift,x,z
\end{verbatim}
                                       
如上文所示，第一个数据块那个1表示该帧中玩家正在按up（方向键向上）键，
第二个数据则表示该帧玩家刚按下了up，且从之前开始就按着shift。

48bit的数据块可以看做48个01变量，这里展示了24个键位的含义，
分别为表示当前帧按下，按中，松开ctrl,右，左，下，上，shift，x，z键。
其他键可能表示Esc和一些特殊按键的三种情况，不过未做实验。

为了解析这些二进制文件，我们编写了Python程序并传到GitHub上 
\footnote{ https://github.com/yiyuezhuo/touhou-replay-decoder }
但其中一些具体的解析的“魔数”的提供是由  threp \footnote{ https://github.com/Fluorohydride/threp } 进行的，
不幸的是其中有一些bug而原始实现的C语言不好调试，所以我们实现了Python版并强化了API。

上述程序的一个功能是将二进制文件转成json文件，这也是我们将作为附件的内容。
但代码里主要使用Python的pickle暂存的文件。
因为数据占用内存太多对后面的贝叶斯推断程序无法执行。解码程序本身可在上面的github页面查到，
转换程序在explore\_help.py中。

虽然做过全部数据的探索，但下面我们只会提到这样的数据，202个回放现在每一个对应6个关卡（stage）的秒序列，
每秒对应一个四个变量的记录，表示这秒60帧中按下shift,ctrl,x按键的帧数，与“绝对运动量”，
即按下一秒内按下四个方向键的帧数和。

其中shift是慢速移动的键，按下这键表示当前的场景比较紧张，需要精细移动。ctrl是跳过对话的键，
表明了此时处于特定的对话阶段。x是“灵击”，表明此时是刷分时刻或危险时刻。
绝对移动量是根据是否当前帧处于慢速移动还是正常移动，在上下左右按键情况加权下的指标。具体来说，该秒内
某帧按住shift时还按下“下”（此时也可以按其他键，类似计算），将在该指数中+2.0，若没有按下shift则加4.5，
若并没有按下“下”则贡献0。虽然计算了互相1s内相互抵消的相对移动量，但没有纳入分析。

\section{探索式分析}

\subsection{轨迹图}

根据东方系列wiki所述\footnote{ http://wikiwiki.jp/thk/?\%C9\%F7\%2FPlayer } 在按着shift时的移动，
即慢速移动，在我们考虑的“梦B”类中为 2像素/秒。而不按着shift时的移动，即快速移动速度为 4.5像素/秒。
故按照这个情况可以绘制一关内玩家控制的机体的移动轨迹，这对于确认二进制分析是否正确也是重要的。

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/touhou1.png}
\caption{时刻1}
\end{minipage}%
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/touhou2.png}
\caption{时刻2}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/touhou3.png}
\caption{时刻3}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/trace2d.png}
\caption{2d轨迹图}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/trace3d.png}
\caption{3d轨迹图}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/trace2dfull.png}
\caption{同关卡全时间2d轨迹图}
\end{minipage}
\end{figure}

上图1,2,3展示了某个回放在第四关开头的三个瞬间，而我们对存档解析出的2d轨迹图各帧的移动轨迹。
考虑到在同一轨迹上移动或停止与速度变化并不能体现在2d轨迹图上，我们还绘制了3d轨迹图。
最后一张图展示了该关整个轨迹。由于玩家控制的自机被摧毁时会重置位置，这个连续的轨迹图并不能反映除了开始一段时间外
的位置情况（但通过取其中一些点将部分轨迹平移可以做到，这里并没有展示。）

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/trace3dsm.png}
\caption{微移移动行为}
\end{minipage}%
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/trace2dstage6.png}
\caption{同回放第六关轨迹}
\end{minipage}
\end{figure}

而从左图是上图那个600帧后的600帧的3d轨迹图中，我们可以从中看到锯齿型（这在2d图中则难以看出，就是一个横线）
看出该类游戏的一个典型行为，即通过“微移”来躲避所谓的“自机狙”，锯齿的产生是因为按一下左键马上松开再按这种行为，
这种行为可以在按住shift的基础上进一步降低平均速度，故而称为“微移”行为。

右图是同一个回放第六关的完全轨迹图，虽然并不能把其当做位置轨迹，
但可以明显的看到很多时间内玩家被困在一块小区域里运动的模式。这与这关的敌人的封锁能力有关。

\subsection{按键情况时序图}

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/pressingShiftFrame.png}
\caption{按帧计的按下shift的0,1序列}
\end{minipage}%
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/pressingShift1.png}
\caption{按秒求和后序列}
\end{minipage}
\end{figure}

如果直接显示当前帧正在按住shift的0,1时序图。将是左图的样子，这样显然很难看出更细致的东西，而按1秒=60帧
\footnote{严格来说，这与玩家真正的秒不一定一致，此指标即所谓的fps，帧每秒。
游戏至多把fps可能升到60以上的时候控制在60，却不能在其低于60的时候将其无损失的提升到60。
不过本文就称60帧为1秒为了方便 }求和后。图就变成了右边那样，显然更加清晰。

前文指出过按住shift表示当时的局势比较紧张，所以可以从按住shift的情况中分辨出各个关卡的特征。
正如下面同一个回放中六个关卡的按秒求和的时序图所示：

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/pressingShift1.png}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/pressingShift2.png}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/pressingShift3.png}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/pressingShift4.png}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/pressingShift5.png}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/pressingShift6.png}
\end{minipage}
\end{figure}

尽管其他按键的时序图也是有趣的，但这里略去，部分信息可以由下面的图反映出来。

\subsection{按时间在各回放上直接求和}

东方的一个关卡分为若干阶段，有的阶段时间固定，有的不固定，有的还根据之前的情况出现或不出现。
玩家则根据策略不同，会选择不同的打法，如“刷分”打法可能会使时间可变的阶段尽可能持续的更久，
而“混关”打法则可能倾向于快速通过以回避遭到损失的不确定性。这一策略的混合下在下图中展示的非常清楚：

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{images/pressingCtrlSum.png}
\caption{在202个回放上在第三关上以按住ctrl帧数求和}
\end{figure}

202个回放在第三关各秒，直接对按住ctrl求和的结果。按住ctrl通常是为了跳过对话，而对话在某些固定阶段过渡时发生，
于是上述峰可以用于划分阶段。而峰的分布反映了混合策略存在的可能性，显然，
如果所有回放中玩家的策略和实施情况一样，则峰应该重叠在一秒上。而这并没有发生，

峰越来越的矮胖除了可以看做独立同分布的间隔叠加的结果外，和后面阶段本身的玩家可控制的时间范围也有关。
而若要仔细识别个别玩家使用的策略或者统计的推论可能策略数，必须借助后面的统计模型。

为了展示ctrl划分的阶段并不是按住ctrl变量内部独有的现象，下面我们在上图基础上画出按住x的情况进行对比：

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/sumCtrlX.png}
\caption{第三关ctrl与X按键}
\end{minipage}%
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/sumCtrlX2.png}
\caption{第六关ctrl与X按键}
\end{minipage}
\end{figure}

如果左图还不明显，我们可以在反映第六关相同关系的右图中明显发现在黑线标出的估计的分界点过后，
x的按键情况也发生了很大变化。所以ctrl是指示阶段变化的很好的变量。

\section{统计分析}


\subsection{分界点问题}

虽然ctrl是个有力的划分变量的只是变量，但既然阶段的存在是客观存在且同时影响四个变量，
那么使用四个变量的信息将给出对阶段分界点更精确的信息。


\subsubsection{模型设定}

符号约定

\begin{tabular}{c|c}
 \hline
 $N$ & 回放总数 \\
 $P$ & 阶段数 \\
 $S$ & 策略数 \\
 $s_i$ & 第i个回放采用的策略 \\
 $Sh_{it}$ & 第$i$个回放在第$t$秒的按住Shift的帧数 \\
 $Ct_{it}$ & 第$i$个回放在第$t$秒的按住Ctrl的帧数 \\
 $X_{it}$ & 第$i$个回放在第$t$秒的按住X的帧数 \\
 $move_{it}$ & 第$i$个回放在第$t$秒的绝对移动量 \\
 $d_{ip}$ & 第$i$个回放在第$p$阶段的持续秒数 \\
 $b_{ip}$ & 第$i$个回放$p$阶段的结束时间 \\
 $p_{it}$ & 第$i$个回放在第$t$秒处于的阶段 \\
  D & 数据集 $D = \{ Sh_{it},Ct_{it},X_{it},move_{it} \quad i = 1,\dots,N \quad t = 1,\dots,P \}$\\
  \hline
\end{tabular}

对联合概率的分层描述：

\begin{align*} % *是去掉公式编号。。上次就被这个坑了
& d_{ip} \sim N(\mu^d_p,\sigma^d_p) \quad i = 1,\dots,N \quad p = 1,\dots,P \\
& b_{ip} = \sum_{h=1}^p d_{ih} \\
& p_{it} = \max( \{ p \mid t < b_{ip} \quad p = 1,\dots,P \} ) \\
& \mu^{Sh}_p \sim Exp(1/\bar{\mu}^{Sh}_p) \quad p = 1,\dots,P \\
& \mu^{Ct}_p \sim Exp(1/\bar{\mu}^{Ct}_p) \\
& \mu^{X}_p \sim Exp(1/\bar{\mu}^{X}_p) \\
& \mu^{move}_p \sim Exp(1/\bar{\mu}^{move}_p) \\
& \sigma^{move}_p \sim Exp(1/\bar{\sigma}^{move}_p) \\
& Sh_{it} \sim Poi(\mu^{Sh}_{p_{it}}) \\
& Ct_{it} \sim Poi(\mu^{Ct}_{p_{it}}) \\
& X_{it} \sim Poi(\mu^{X}_{p_{it}}) \\
& move_{it} \sim N(\mu^{move}_{p_{it}},\sigma^{move}_{p_{it}}) \\
\end{align*}

其中$poi$指泊松分布，$Exp$指指数分布。$p_{it}$其实就是按所处阶段分类的形式写法，其对推断来了困难。

这里$\bar{\mu}^{Y}_{p}$,（$Y$可能为$Sh,Ct,X,move,d$等）为给定的先验分布的参数。
分层地控制了随机参数$\mu^{Y}_p$的先验分布。它们采用指数分布是为了连续且保持正数性。
这些值以上面提到的的秒求和方法矩估计而得。
$Sh_{ti},Ct_{it},X_{it}$服从泊松分布是因为取值为整数。

该模型指定的四个变量$Sh,Ct,X,move$在给定其所在状态$p_{it}$下互相条件独立，同时在$i,t$内部上也独立。

该模型的可观测变量是$Sh_{it},Ct_{it},X_{it},move_{it}$。
重要的潜在变量是$d_{ip}$，显然阶段内的四个变量的共性将同时为阶段持续时间
或者说分割点提供信息，这应该比平凡的，如之前展示的根据ctrl计算的估计的分割点更强。


\subsubsection{推断}

下面均指在一个特定关卡内，由于内存限制没有做跨关卡的分析。

为了增加运行效率和编写模型方便，使用了Edward，一个用来概率编程的Python库\cite{edward}。
由于模型的复杂性，为了求解给定数据的隐变量分布与随机参数的后验分布，必须借助近似方法。
流行的近似后验分布的方法有MCMC（马尔科夫链蒙特卡洛法）和变分推断，这里本来是打算采用经典的Metropolis-Hastings算法，
\cite{metropolis}
但一次抽样全部维度接受率太低，加上一次采样本来就要消耗很多内存，为了尽可能采集到有效地样本，
换用部分的Gibbs采样\cite{gibbs}，Edward或PyMC3之类的概率编程框架由于基于tensorflow或theano这些构建计算图的框架，
所以真正的ElementWise的Gibbs采样开销太高，故而它们都没有提供真正的Gibbs采样法。
我们自己实现了一个在几个向量之间轮换采样的算法，可以说介于MH与Gibbs之间，但内存开销已经处于无法使用的临界点中。

之后的proposal分布未经说明均为均值为上一次采样值的正态分布。MCMC的初始点均为对应先验分布的期望。迭代30000次。

MCMC的有效性可以从轨迹是否收敛的到某些值附近看出

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/traceCtrl.png}
\caption{$\mu_{Ct} \mid D $的轨迹}
\end{minipage}%
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/traceShift.png}
\caption{$\mu_{Sh} \mid D$的轨迹}
\end{minipage}
\end{figure}

可以看出的确收敛到了某些值附近。

取30000次迭代中的后15000次作为充分遍历的解，MH算法本身接受率略低，如下图所示：

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{images/traceTwice.png}
\caption{第一个与第二个回放的第一阶段长度的轨迹,$d_{11},d_{12}$}
\end{figure}

但是由于可以合并所有回放的信息，仍然可以有足够的样本做出后验估计。如下图所示：

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{images/dhist.png}
\caption{第一关第一阶段长度的后验分布}
\end{figure}

将各个阶段分界点（阶段求累积和）分布覆盖在按住shift与按住ctrl图上将看的清楚。

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/biHistShift.png}
\caption{shift与分界点分布比较}
\end{minipage}%
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/biHistCtrl.png}
\caption{ctrl与分界点分布比较}
\end{minipage}
\end{figure}

可以看出后验分布在光看shift与ctrl的话，所指示的分界点的中间位置，
这意味着它同时吸收了两者（以及另外两个变量x与move）的信息。

\subsection{策略识别}

探索式分析指出了异质策略存在的可能性，之前的图表则显示出第一二个回放的的第一阶段时长两个隐变量的先验分布虽然相同，
但在给定数据下呈现显著不同的后验分布。虽然这一异质性的捕捉是很好的，但是它们出自同一先验分布的假设可能并不有效，
一个有趣的问题就是是否存在策略的分类，其使得对数据的拟合更加有效，同时也印证了之前的“刷分”与“速攻”讨论所暗示的可能。

\subsubsection{模型设定}

模型的主要变化就是让每个回放以一个离散概率从一组控制时长的随机参数中选择一组：

\begin{align*} % *是去掉公式编号。。上次就被这个坑了
& \mu^d_{sp} \sim N(\bar{\mu}^d_{sp},\bar{\sigma}^d_{sp}) \quad s = 1,\dots,S \\
& w_s \sim N(0,1) \quad s = 1,\dots,S \\
& WS = softmax(w_1,\dots,w_S) \\
& P(s_i=s) = WS_s \\
& d_{ip} \sim N(\mu^d_{s_i,p},\mu^d_{s_i,p} / \bar{c}) \quad i = 1,\dots,N \quad p = 1,\dots,P \\
& b_{ip} = \sum_{h=1}^p d_{ih} \\
& p_{it} = \max( \{ p \mid t < b_{ip} \quad p = 1,\dots,P \} ) \\
& \mu^{Sh}_p \sim Exp(1/\bar{\mu}^{Sh}_p) \quad p = 1,\dots,P \\
& \mu^{Ct}_p \sim Exp(1/\bar{\mu}^{Ct}_p) \\
& \mu^{X}_p \sim Exp(1/\bar{\mu}^{X}_p) \\
& \mu^{move}_p \sim Exp(1/\bar{\mu}^{move}_p) \\
& \sigma^{move}_p \sim Exp(1/\bar{\sigma}^{move}_p) \\
& Sh_{it} \sim Poi(\mu^{Sh}_{p_{it}}) \\
& Ct_{it} \sim Poi(\mu^{Ct}_{p_{it}}) \\
& X_{it} \sim Poi(\mu^{X}_{p_{it}}) \\
& move_{it} \sim N(\mu^{move}_{p_{it}},\sigma^{move}_{p_{it}}) \\
\end{align*}

处于对无知的反映,新参数$\bar{\mu}^d_{sp}$是之前的$\bar{\mu}^d_{p}$加上独立的噪声生成的。

其中$softmax(x_i)=exp(x_i)/(\sum_{i=1} exp(x_i))$.



这里为了增加接受率使用了前面提到的MH算法与Gibbs算法的混合体进行估计。这里展示的情况设了三个策略，

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{images/classific3.png}
\caption{$WS \mid D$(分类概率)轨迹}
\end{figure}

可以注意到红色类概率趋于0，这倾向于给出存在两个类的比较合适的结论。

前四个阶段的持续时间（最后一个阶段的持续时间是上限减前四个的和，未标出）的轨迹

\begin{figure}[H]
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/gb.png}
\caption{$\mu^d_{s1} \mid D $的轨迹}
\end{minipage}%
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/gb2.png}
\caption{$\mu^d_{s2} \mid D$的轨迹}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/gb3.png}
\caption{$\mu^d_{s3} \mid D$的轨迹}
\end{minipage}%
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2.2in]{images/gb4.png}
\caption{$\mu^d_{s4} \mid D的轨迹$}
\end{minipage}
\end{figure}

从图中可以看出被赋予概率更少的绿色类在除第二个阶段外，持续时间都明显高于红色类。
如果要用“混关”与“刷分”的观点想的话，这反映了刷分（持续时间较短）的人可能占比较少。

\section{结论}

我们通过对弹幕游戏操作数据进行了处理，并做了探索式分析与统计分析。以此建立了弹幕操作序列的统计模型，
可以以此作为更广泛的游戏类型的分段的分析框架。而混合策略则提供了一种对更广泛游戏的策略分析范式。

不得不指出的是，本文的实验深受随机采样法“随机性”的困扰，反映了这种方法的使用方式还需要改进。
比如时长选择正态分布看来是个失败的决定，本来认为其出现负值是有其意义的，但其意义带来了对称性，造成了识别的困难。
这在最后的实验中也有所体现，似乎并没有收敛完全，不过内存并不足以支持更多的迭代，MCMC的计算开销也很大，
采用我们的算法进行分层模型模拟30000轮需要2606s，虽然Edward自带的MH算法更快一些，但效果不佳。

%参考文献
\begin{thebibliography}{9}%宽度9
 \bibitem{alphago} Silver D, Huang A, Maddison C J, et al. Mastering the game of Go with deep neural networks and tree search[J]. Nature, 2016, 529(7587): 484-489. 	
 \bibitem{starcraft} Hostetler J, Dereszynski E W, Dietterich T G, et al. Inferring strategies from limited reconnaissance in real-time strategy games[J]. arXiv preprint arXiv:1210.4880, 2012.
 \bibitem{atari} Mnih V, Kavukcuoglu K, Silver D, et al. Playing atari with deep reinforcement learning[J]. arXiv preprint arXiv:1312.5602, 2013.
 \bibitem{edward} Tran D, Kucukelbir A, Dieng A B, et al. Edward: A library for probabilistic modeling, inference, and criticism[J]. arXiv preprint arXiv:1610.09787, 2016.
 \bibitem{metropolis} Hastings W K. Monte Carlo sampling methods using Markov chains and their applications[J]. Biometrika, 1970, 57(1): 97-109..
 \bibitem{gibbs} Geman S, Geman D. Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images[J]. IEEE Transactions on pattern analysis and machine intelligence, 1984 (6): 721-741.
\end{thebibliography}

\newpage
%附录
\appendix

所有分析相关的程序均在Jupyter notebook Python Kernal下运行。所有实验记录，图片与源代码和本文的tex源码可于
作者卓越羿的github上获取（https://github.com/yiyuezhuo/touhou-replay-research），回放解析代码在脚注中已给出地址，
附带数据仅包括用于分析的pickle解析过的数据与jupyter notebook文件，与
附录中的代码仅包括调用Edward构造两个统计模型的核心代码，不可独立执行。

分界点模型

以下仅为核心定义代码。欲独立运行，用jupyter notebook打开model-baseline.ipynb。

\begin{verbatim}

# MODEL

#durations = ed.models.Normal(loc = [80.0,51.0], scale=[3.0,10.0], sample_shape=replay_num) # 202 * 2 matrix
durations = ed.models.Normal(loc = time_length[:,0], scale=time_length[:,1], sample_shape=replay_num) # 202 * 4 matrix
breaks = tf.cumsum(durations, axis=1) # 202 * 4 matrix
#_breaks = tf.transpose(tf.reshape(tf.tile(breaks,(stage_length, 1)),(stage_length,replay_num,2)),(1,2,0))  
_breaks = tf.transpose(tf.reshape(tf.tile(breaks,(stage_length, 1)),(stage_length,replay_num,durations_num)),(1,2,0))  
_mask = tf.where(_time_axis > _breaks, 
                 tf.ones((replay_num, durations_num, stage_length),dtype=tf.int32), 
                 tf.zeros((replay_num, durations_num, stage_length),dtype=tf.int32))
index = tf.reduce_sum(_mask, axis=1)


_shift_mu = meansd[:,0,0]
_ctrl_mu  = meansd[:,1,0]
_x_mu     = meansd[:,2,0]
_move_mu  = meansd[:,3,0]
_move_sd  = meansd[:,3,1]


shift_mu = ed.models.Exponential(rate = 1/_shift_mu)
ctrl_mu = ed.models.Exponential(rate = 1/_ctrl_mu)
x_mu = ed.models.Exponential(rate = 1/_x_mu)
move_mu = ed.models.Exponential(rate = 1/_move_mu) 
move_sd = ed.models.Exponential(rate = 1/_move_sd) 

def share_params_into_period(var, index):
    var_list = []
    for i in range(replay_num):
        var_list.append(tf.gather(var,index[i]))
    var_along_replay = tf.stack(var_list)
    return var_along_replay

shift_mu_time = share_params_into_period(shift_mu, index)
ctrl_mu_time = share_params_into_period(ctrl_mu, index)
x_mu_time = share_params_into_period(x_mu, index)
move_mu_time = share_params_into_period(move_mu, index)
move_sd_time = share_params_into_period(move_sd, index)

pressing_shift = ed.models.Poisson(rate = shift_mu_time)
pressing_ctrl = ed.models.Poisson(rate = ctrl_mu_time)
pressing_x = ed.models.Poisson(rate = x_mu_time)
move = ed.models.Normal(loc = shift_mu_time, scale = move_sd_time)

# Inference
T = 30000

idurations = np.ones([T, replay_num, durations_num],dtype='float32')
idurations[0,:,:] = np.array(time_length[:,0], dtype='float32')
qdurations = ed.models.Empirical(tf.Variable(idurations))

ishift_mu = np.ones([T,period_num],dtype='float32')
ishift_mu[0,:] = _shift_mu
qshift_mu = ed.models.Empirical(tf.Variable(ishift_mu))

ictrl_mu = np.ones([T,period_num],dtype='float32')
ictrl_mu[0,:] = _ctrl_mu
qctrl_mu = ed.models.Empirical(tf.Variable(ictrl_mu))

ix_mu = np.ones([T,period_num],dtype='float32')
ix_mu[0,:] = _x_mu
qx_mu = ed.models.Empirical(tf.Variable(ix_mu))

imove_mu = np.ones([T,period_num],dtype='float32')
imove_mu[0,:] = _move_mu
qmove_mu = ed.models.Empirical(tf.Variable(imove_mu))

imove_sd = np.ones([T,period_num],dtype='float32')
imove_sd[0,:] = _move_sd
qmove_sd = ed.models.Empirical(tf.Variable(imove_sd))


# proposal variable

gdurations = ed.models.Normal(loc = durations, scale = np.tile([0.1]*durations_num,[replay_num,1]).astype('float32'))

poi_scale = 0.1 
sd_scale = 0.1 

gshift_mu = ed.models.Normal(loc = shift_mu, scale = [poi_scale]*period_num)
gctrl_mu = ed.models.Normal(loc = ctrl_mu, scale = [poi_scale]*period_num)
gx_mu = ed.models.Normal(loc = x_mu, scale = [poi_scale]*period_num)
gmove_mu = ed.models.Normal(loc = move_mu, scale = [0.01]*period_num)
gmove_sd = ed.models.Normal(loc = move_sd, scale = [sd_scale]*period_num)

inference = ed.MetropolisHastings({durations: qdurations, 
                                   shift_mu: qshift_mu, ctrl_mu: qctrl_mu, x_mu: qx_mu,move_mu: qmove_mu,move_sd: qmove_sd},
                      proposal_vars = {durations: gdurations, 
                                       shift_mu: gshift_mu, ctrl_mu: gctrl_mu, x_mu: gx_mu,move_mu: gmove_mu,move_sd: gmove_sd},
                      data = {pressing_shift: stage[:,0,:], pressing_ctrl: stage[:,1,:], pressing_x: stage[:,2,:], move: stage[:,3,:]})
					  
inference.run()

\end{verbatim}


混合策略模型

欲独立运行，用jupyter notebook打开model5.ipynb。

\begin{verbatim}


S = 3

_idurations_loc_loc = np.tile(time_length[:,0],(S,1))
_idurations_loc_scale = np.tile(time_length[:,1],(S,1))
_idurations_loc_loc = np.random.normal(loc = _idurations_loc_loc, scale = 3.0).astype('float32')

# Model



durations_loc_param = Normal(loc = _idurations_loc_loc, scale = _idurations_loc_scale) 


loc_weights = Normal(loc=np.zeros(S,dtype='float32'),scale=np.ones(S,dtype='float32'))
loc_index = ed.models.Categorical(logits = loc_weights,sample_shape = replay_num)

durations_loc = tf.gather(durations_loc_param, loc_index) 
durations_scale =  durations_loc / 10.0 

durations = ed.models.Normal(loc = durations_loc, scale=durations_scale) # 202 * 2 matrix # yep we remove the sample_shape to fit new extent


breaks = tf.cumsum(durations, axis=1) # 202 * 4 matrix
#_breaks = tf.transpose(tf.reshape(tf.tile(breaks,(stage_length, 1)),(stage_length,replay_num,2)),(1,2,0))  
_breaks = tf.transpose(tf.reshape(tf.tile(breaks,(stage_length, 1)),(stage_length,replay_num,durations_num)),(1,2,0))  
_mask = tf.where(_time_axis > _breaks, 
                 tf.ones((replay_num, durations_num, stage_length),dtype=tf.int32), 
                 tf.zeros((replay_num, durations_num, stage_length),dtype=tf.int32))
index = tf.reduce_sum(_mask, axis=1)

_shift_mu = meansd[:,0,0]
_ctrl_mu  = meansd[:,1,0]
_x_mu     = meansd[:,2,0]
_move_mu  = meansd[:,3,0]
_move_sd  = meansd[:,3,1] / 10


shift_mu = ed.models.Exponential(rate = 1/_shift_mu)
ctrl_mu = ed.models.Exponential(rate = 1/_ctrl_mu)
x_mu = ed.models.Exponential(rate = 1/_x_mu)
move_mu = ed.models.Exponential(rate = 1/_move_mu) 
move_sd = ed.models.Exponential(rate = 1/_move_sd) 

def share_params_into_period(var, index):
    var_list = []
    for i in range(replay_num):
        var_list.append(tf.gather(var,index[i]))
    var_along_replay = tf.stack(var_list)
    return var_along_replay

shift_mu_time = share_params_into_period(shift_mu, index)
ctrl_mu_time = share_params_into_period(ctrl_mu, index)
x_mu_time = share_params_into_period(x_mu, index)
move_mu_time = share_params_into_period(move_mu, index)
move_sd_time = share_params_into_period(move_sd, index)

pressing_shift = ed.models.Poisson(rate = shift_mu_time)
pressing_ctrl = ed.models.Poisson(rate = ctrl_mu_time)
pressing_x = ed.models.Poisson(rate = x_mu_time)
move = ed.models.Normal(loc = shift_mu_time, scale = move_sd_time)

# Inference
T = 30000


idurations_loc_param = np.ones([T, S, durations_num],dtype='float32')
idurations_loc_param[0,:,:] = _idurations_loc_loc #_idurations_loc_param
qdurations_loc_param = ed.models.Empirical(tf.Variable(idurations_loc_param))


iloc_weights = np.zeros([T,S],dtype='float32') 
qloc_weights = ed.models.Empirical(tf.Variable(iloc_weights))

ishift_mu = np.ones([T,period_num],dtype='float32')
ishift_mu[0,:] = _shift_mu
qshift_mu = ed.models.Empirical(tf.Variable(ishift_mu))

ictrl_mu = np.ones([T,period_num],dtype='float32')
ictrl_mu[0,:] = _ctrl_mu
qctrl_mu = ed.models.Empirical(tf.Variable(ictrl_mu))

ix_mu = np.ones([T,period_num],dtype='float32')
ix_mu[0,:] = _x_mu
qx_mu = ed.models.Empirical(tf.Variable(ix_mu))

imove_mu = np.ones([T,period_num],dtype='float32')
imove_mu[0,:] = _move_mu
qmove_mu = ed.models.Empirical(tf.Variable(imove_mu))

imove_sd = np.ones([T,period_num],dtype='float32')
imove_sd[0,:] = _move_sd
qmove_sd = ed.models.Empirical(tf.Variable(imove_sd))


# proposal variable

gdurations_loc_param = Normal(loc = durations_loc_param, scale = np.ones([S,durations_num],dtype='float32')*0.1)
gloc_weights = Normal(loc = loc_weights, scale = np.ones(S,dtype='float32')*0.1)

poi_scale = 0.1 
sd_scale = 0.1 

gshift_mu = ed.models.Normal(loc = shift_mu, scale = [poi_scale]*period_num)
gctrl_mu = ed.models.Normal(loc = ctrl_mu, scale = [poi_scale]*period_num)
gx_mu = ed.models.Normal(loc = x_mu, scale = [poi_scale]*period_num)
gmove_mu = ed.models.Normal(loc = move_mu, scale = [0.01]*period_num)
gmove_sd = ed.models.Normal(loc = move_sd, scale = [sd_scale]*period_num)

# proposal variable

#gdurations = ed.models.Normal(loc = durations, scale = np.tile([0.1,0.1],[replay_num,1]).astype('float32'))

#gdurations_loc_param = Normal(loc = durations_loc_param, scale = [[0.1,0.1],[0.1,0.1],[0.1,0.1]])
gdurations_loc_param = Normal(loc = durations_loc_param, scale = np.ones([S,durations_num],dtype='float32')*0.1)
#gloc_weights = Normal(loc = loc_weights, scale = [0.1,0.1,0.1])
gloc_weights = Normal(loc = loc_weights, scale = np.ones(S,dtype='float32')*0.1)

poi_scale = 0.1 ]
sd_scale = 0.1 

gshift_mu = ed.models.Normal(loc = shift_mu, scale = [poi_scale]*period_num)
gctrl_mu = ed.models.Normal(loc = ctrl_mu, scale = [poi_scale]*period_num)
gx_mu = ed.models.Normal(loc = x_mu, scale = [poi_scale]*period_num)
gmove_mu = ed.models.Normal(loc = move_mu, scale = [0.01]*period_num)
gmove_sd = ed.models.Normal(loc = move_sd, scale = [sd_scale]*period_num)

from metropolis_hastings_y import MetropolisHastingsY
inference = MetropolisHastingsY({durations_loc_param: qdurations_loc_param, loc_weights: qloc_weights,
                                   shift_mu: qshift_mu, ctrl_mu: qctrl_mu, x_mu: qx_mu,move_mu: qmove_mu,move_sd: qmove_sd},
                      proposal_vars = {durations_loc_param: gdurations_loc_param, loc_weights: gloc_weights,
                                       shift_mu: gshift_mu, ctrl_mu: gctrl_mu, x_mu: gx_mu,move_mu: gmove_mu,move_sd: gmove_sd},
                      data = {pressing_shift: stage[:,0,:], pressing_ctrl: stage[:,1,:], pressing_x: stage[:,2,:], move: stage[:,3,:]})
					  
inference.run()

\end{verbatim}



\end{document}